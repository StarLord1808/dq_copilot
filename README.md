# Data Quality Copilot CLI

A CLI AI agent that profiles tables, detects data quality issues, and generates dbt-style tests automatically.

## Problem Statement

Data quality is critical for reliable analytics and ML pipelines. However, manually writing data quality tests is time-consuming and error-prone. This tool automates the process by:

1. **Profiling** tables to understand their structure and statistics
2. **Detecting** common data quality issues using rule-based heuristics
3. **Generating** intelligent test suggestions using LLM
4. **Outputting** dbt-compatible YAML test files

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CLI       â”‚  Click-based command interface
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â–º TableLoaderAgent      (Load CSV/Parquet â†’ DataFrame)
       â”‚
       â”œâ”€â”€â–º ProfilerAgent         (Compute column statistics)
       â”‚
       â”œâ”€â”€â–º AnomalyDetectorAgent  (Rule-based issue detection)
       â”‚
       â”œâ”€â”€â–º TestGeneratorAgent    (LLM-powered test suggestions)
       â”‚
       â”œâ”€â”€â–º YamlGenerator         (dbt YAML output)
       â”‚
       â””â”€â”€â–º ReportRendererAgent   (Terminal report)
```

### Agent Responsibilities

- **TableLoaderAgent**: Loads CSV and Parquet files with error handling
- **ProfilerAgent**: Computes per-column stats (dtype, nulls, distinct count, min/max, examples)
- **AnomalyDetectorAgent**: Detects 4 issue types:
  - High null rate (>30%)
  - Non-unique ID columns
  - Constant columns (â‰¤1 distinct value)
  - Negative values in amount/count fields
- **TestGeneratorAgent**: Uses OpenAI GPT-4 to suggest dbt tests (with rule-based fallback)
- **YamlGenerator**: Transforms suggestions into dbt `version: 2` YAML
- **ReportRendererAgent**: Rich terminal output with tables and colors

## Installation

```bash
cd /home/jiraiya/codebase/ai-agent/dq-copilot
pip install -e .
```

## Usage

### Profile Command (No LLM Required)

Profile a table and generate statistics only:

```bash
dq-copilot profile --table-path examples/orders.csv --table-name orders
```

**Output:**
- `orders_profile.json` - Detailed column statistics

### Run Command (Full Pipeline with LLM)

Run the complete data quality analysis:

```bash
export OPENAI_API_KEY="your-api-key-here"
dq-copilot run --table-path examples/orders.csv --table-name orders
```

**Output:**
- `orders_profile.json` - Column statistics
- `tests/orders_tests.yml` - dbt test file

### Options

```
--table-path PATH    Path to CSV or Parquet file (required)
--table-name NAME    Table name for metadata (required)
--output-dir DIR     Output directory (default: current directory)
--api-key KEY        OpenAI API key (or set OPENAI_API_KEY env var)
```

## Example Demo

The included `examples/orders.csv` dataset contains intentional anomalies:

| Anomaly Type | Column | Issue |
|--------------|--------|-------|
| Non-unique ID | `order_id` | Duplicate value 1001 |
| High null rate | `customer_name` | 40% null values |
| Constant column | `status` | All values are "pending" |
| Negative values | `amount` | Contains -50.00 and -25.00 |

**Run the demo:**

```bash
cd /home/jiraiya/codebase/ai-agent/dq-copilot
dq-copilot run --table-path examples/orders.csv --table-name orders
```

**Expected output:**

```
Loading table from examples/orders.csv...
âœ“ Loaded 20 rows, 6 columns
Profiling table...
âœ“ Profile written to orders_profile.json
Detecting anomalies...
âœ“ Found 4 potential issues
Generating test suggestions...
âœ“ Generated 6 test suggestions
Generating dbt tests YAML...
âœ“ Tests written to tests/orders_tests.yml

================================================================================

â”Œâ”€ ğŸ“Š Table Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Table Name:    orders                                                      â”‚
â”‚ Row Count:     20                                                          â”‚
â”‚ Column Count:  6                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âš ï¸  Detected Issues
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Severity â”‚ Column        â”‚ Issue Type       â”‚ Details                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ERROR    â”‚ order_id      â”‚ non_unique_id    â”‚ ID column is only 95.0%...  â”‚
â”‚ WARNING  â”‚ customer_name â”‚ high_null_rate   â”‚ Column has 40.0% null...    â”‚
â”‚ WARNING  â”‚ amount        â”‚ negative_values  â”‚ Contains negative values... â”‚
â”‚ INFO     â”‚ status        â”‚ constant_column  â”‚ Column has only 1 distinct..â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ âœ… Suggested Tests â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Total Tests:  6                                                            â”‚
â”‚ Description:  LLM-generated test suggestions                               â”‚
â”‚                                                                            â”‚
â”‚ Tests by Type:                                                             â”‚
â”‚   â€¢ not_null:                                3                             â”‚
â”‚   â€¢ unique:                                  1                             â”‚
â”‚   â€¢ expect_column_values_to_be_between:      2                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ ğŸ“ Output Files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Profile JSON:  orders_profile.json                                         â”‚
â”‚ Tests YAML:    tests/orders_tests.yml                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Configuration

### LLM Provider

The tool uses OpenAI GPT-4 by default. Set your API key:

```bash
export OPENAI_API_KEY="sk-..."
```

If no API key is provided, the tool falls back to rule-based test generation (limited but functional).

### Anomaly Detection Thresholds

Thresholds are configurable in the code:

```python
detector = AnomalyDetectorAgent(
    high_null_threshold=0.3,      # 30% null rate
    constant_threshold=1,          # â‰¤1 distinct value
    id_uniqueness_threshold=1.0    # 100% unique for IDs
)
```

## Dependencies

- `click` - CLI framework
- `pandas` - Data manipulation
- `pyarrow` - Parquet support
- `openai` - LLM integration
- `pyyaml` - YAML generation
- `rich` - Terminal formatting

## Development

```bash
# Install with dev dependencies
pip install -e ".[dev]"

# Run tests (if added)
pytest

# Format code
black dq_copilot/
ruff check dq_copilot/
```

## License

MIT
